# Fake Review Detection

Detection of fake online reviews using semi-supervised and supervised learning approaches.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Methodology](#methodology)
- [Requirements](#requirements)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project implements machine learning models to detect fake online reviews. It uses both semi-supervised and supervised learning techniques, including Random Forest and Naive Bayes classifiers. The system analyzes various features extracted from reviews, reviewers, and restaurants to identify potentially fraudulent reviews.

## âœ¨ Features

- **Semi-Supervised Learning**: Utilizes pseudo-labeling to leverage unlabeled data
- **Multiple Algorithms**: Implements Random Forest and Naive Bayes classifiers
- **Feature Engineering**: Extracts meaningful features including:
  - Maximum Number of Reviews (MNR)
  - Review Length (RL)
  - Rating Deviation (RD)
  - Maximum Content Similarity
- **Data Preprocessing**: Comprehensive data cleaning and text preprocessing
- **Model Evaluation**: Detailed metrics including accuracy, precision, recall, and F1-score

## ğŸ“ Project Structure

```
fake-review-detection/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ fake_review_detection/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_loader.py      # Database loading functionality
â”‚       â”œâ”€â”€ data_processor.py   # Data cleaning and preprocessing
â”‚       â”œâ”€â”€ feature_engineer.py # Feature engineering
â”‚       â”œâ”€â”€ models.py           # ML model implementations
â”‚       â”œâ”€â”€ utils.py            # Utility functions
â”‚       â””â”€â”€ main.py             # Main pipeline
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw data files (e.g., SQLite database)
â”‚   â””â”€â”€ processed/              # Processed data files
â”œâ”€â”€ models/                     # Saved model files
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for exploration
â”œâ”€â”€ tests/                      # Unit tests
â”œâ”€â”€ docs/                       # Documentation
â”œâ”€â”€ main.py                     # Entry point script
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ pyproject.toml             # Project configuration
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Installation

### Prerequisites

- Python 3.9 or higher
- pip (Python package manager)

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/fake-review-detection.git
   cd fake-review-detection
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Download NLTK data** (if not automatically downloaded)
   ```python
   import nltk
   nltk.download('punkt')
   nltk.download('stopwords')
   ```

5. **Prepare your data**
   - Place your SQLite database file (`yelpResData.db`) in the `data/raw/` directory
   - The database should contain tables: `review`, `reviewer`, and `restaurant`

## ğŸ’» Usage

### Basic Usage

Run the main script to execute the complete pipeline:

```bash
python main.py
```

### Using as a Package

You can also import and use the modules in your own code:

```python
from src.fake_review_detection import (
    load_data,
    DataProcessor,
    FeatureEngineer,
    SemiSupervisedLearner
)
from sklearn.ensemble import RandomForestClassifier

# Load and process data
df = load_data()
processor = DataProcessor()
df = processor.clean(df)

# Engineer features
feature_engineer = FeatureEngineer()
df = feature_engineer.create_features(df)

# Train model
model = RandomForestClassifier(random_state=42)
learner = SemiSupervisedLearner(model, algorithm_name='Random Forest')
metrics = learner.train(df, threshold=0.7, iterations=15)
```

### Custom Configuration

You can customize the training parameters:

```python
learner = SemiSupervisedLearner(model, algorithm_name='My Model')
metrics = learner.train(
    df,
    threshold=0.8,      # Confidence threshold for pseudo-labeling
    iterations=20,       # Number of semi-supervised iterations
    test_size=0.2,       # Test set proportion
    random_state=42      # Random seed
)
```

## ğŸ”¬ Methodology

### Data Processing Pipeline

1. **Data Loading**: Loads review, reviewer, and restaurant data from SQLite database
2. **Data Cleaning**: 
   - Removes stopwords
   - Tokenizes text
   - Normalizes dates
   - Converts text to lowercase
3. **Feature Engineering**:
   - **MNR**: Normalized maximum number of reviews per reviewer per date
   - **RL**: Review length (word count)
   - **RD**: Rating deviation from restaurant average
   - **Maximum Content Similarity**: Cosine similarity between reviewer's reviews
4. **Data Balancing**: Under-sampling to balance fake and authentic reviews
5. **Model Training**: Semi-supervised learning with pseudo-labeling

### Semi-Supervised Learning

The semi-supervised approach:
1. Splits data into training and test sets
2. Trains on labeled training data
3. Predicts on test set with confidence scores
4. Adds high-confidence predictions to training set
5. Repeats until convergence or max iterations

### Models

- **Random Forest**: Ensemble method with 500 trees, entropy criterion
- **Naive Bayes**: Gaussian Naive Bayes classifier

## ğŸ“Š Evaluation Metrics

The models are evaluated using:
- **Accuracy**: Overall correctness
- **Precision**: True positives / (True positives + False positives)
- **Recall**: True positives / (True positives + False negatives)
- **F1-Score**: Harmonic mean of precision and recall
- **Confusion Matrix**: Detailed classification breakdown

## ğŸ“¦ Requirements

See `requirements.txt` for the complete list. Key dependencies:

- `pandas>=2.2.0` - Data manipulation
- `numpy>=1.26.0` - Numerical computing
- `scikit-learn>=1.4.0` - Machine learning
- `nltk>=3.8.1` - Natural language processing
- `matplotlib>=3.8.0` - Visualization
- `seaborn>=0.13.0` - Statistical visualization
- `tqdm>=4.66.0` - Progress bars

## ğŸ§ª Testing

Run tests (when available):

```bash
pytest tests/
```

## ğŸ“ Notes

- The project expects a SQLite database with specific schema
- Default database path: `data/raw/yelpResData.db`
- Models use random seeds for reproducibility
- Processing time depends on dataset size

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Author

Manish Morla - https://github.com/manishmorla

## ğŸ™ Acknowledgments

- Yelp dataset (if used)
- Scikit-learn community
- NLTK contributors

---

**Note**: Remember to update the database path and author information in the configuration files before sharing.
